{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# YouTube Success ML: Modeling Readiness\n\nThis notebook validates model-readiness assumptions before retraining.\n\n## Objectives\n- Verify feature/target contract integrity\n- Validate train/test split behavior\n- Review categorical cardinality\n- Inspect target distributions"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Environment Setup"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pathlib import Path\nimport sys\n\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\n\nROOT = Path.cwd().resolve()\nif not (ROOT / \"src\").exists() and (ROOT.parent / \"src\").exists():\n    ROOT = ROOT.parent\nsys.path.insert(0, str(ROOT / \"src\"))\n\nfrom youtube_success_ml.config import DEFAULT_DATA_PATH\nfrom youtube_success_ml.data.loader import load_dataset\nfrom youtube_success_ml.models.supervised import FEATURE_COLUMNS, TARGET_COLUMNS"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Load Dataset + Contract Check"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "df = load_dataset(DEFAULT_DATA_PATH)\n\nprint(f\"rows: {len(df)}\")\nprint(f\"columns: {len(df.columns)}\")\nprint(\"feature columns:\", FEATURE_COLUMNS)\nprint(\"target columns :\", TARGET_COLUMNS)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "missing_feature_cols = [c for c in FEATURE_COLUMNS if c not in df.columns]\nmissing_target_cols = [c for c in TARGET_COLUMNS.values() if c not in df.columns]\n\nprint(\"missing features:\", missing_feature_cols)\nprint(\"missing targets :\", missing_target_cols)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "contract_snapshot = df[FEATURE_COLUMNS + list(TARGET_COLUMNS.values())].head(10)\ncontract_snapshot"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Train/Test Split Sanity"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "X = df[FEATURE_COLUMNS]\ny = df[\"growth_target\"]\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    random_state=42,\n)\n\nprint(f\"train size: {len(X_train)}\")\nprint(f\"test size : {len(X_test)}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Categorical Coverage"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "print(\"category cardinality:\", df[\"category\"].nunique())\nprint(\"country cardinality :\", df[\"country\"].nunique())\n\ndf[[\"category\", \"country\"]].agg([\"nunique\"])"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Target Distribution Snapshot"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "target_snapshot = df[[\"subscribers\", \"highest_yearly_earnings\", \"growth_target\"]].copy()\ntarget_snapshot = target_snapshot.melt(var_name=\"target\", value_name=\"value\")\n\npx.box(target_snapshot, x=\"target\", y=\"value\", points=False, title=\"Target Distribution Snapshot\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Processed CSV Availability Check"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "processed_csv = ROOT / \"data\" / \"global_youtube_statistics_processed.csv\"\nif processed_csv.exists():\n    check_df = pd.read_csv(processed_csv)\n    print(\"processed csv exists:\", processed_csv)\n    print(\"processed csv shape :\", check_df.shape)\nelse:\n    print(\"processed csv not found; run analysis/scripts/export_processed_dataset.py\")"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
